[INFO] 2020-04-28 09:45:08 > The Input Parameters:
[INFO] 2020-04-28 09:45:08 > project_name => None
[INFO] 2020-04-28 09:45:08 > project_raw_dir => None
[INFO] 2020-04-28 09:45:08 > project_processed_dir => None
[INFO] 2020-04-28 09:45:08 > project_config => None
[INFO] 2020-04-28 09:45:08 > project_log => None
[INFO] 2020-04-28 09:45:08 > project_checkpoint => None
[INFO] 2020-04-28 09:45:08 > phase => val
[INFO] 2020-04-28 09:45:08 > source => None
[INFO] 2020-04-28 09:45:08 > checkpoint => None
[INFO] 2020-04-28 09:45:08 > num_candidates => 3
[INFO] 2020-04-28 09:45:08 > save_result => None
[INFO] 2020-04-28 09:45:08 > share_dictionary => False
[INFO] 2020-04-28 09:45:08 > device => cpu
[INFO] 2020-04-28 09:45:08 > gpu_idx => [0]
[INFO] 2020-04-28 09:45:08 > dataset_limit => None
[INFO] 2020-04-28 09:45:08 > print_every => 1
[INFO] 2020-04-28 09:45:08 > save_every => 1
[INFO] 2020-04-28 09:45:08 > vocabulary_size => None
[INFO] 2020-04-28 09:45:08 > positional_encoding => False
[INFO] 2020-04-28 09:45:08 > d_model => 128
[INFO] 2020-04-28 09:45:08 > layers_count => 1
[INFO] 2020-04-28 09:45:08 > heads_count => 2
[INFO] 2020-04-28 09:45:08 > d_ff => 1
[INFO] 2020-04-28 09:45:08 > dropout_prob => 0.1
[INFO] 2020-04-28 09:45:08 > label_smoothing => 0.1
[INFO] 2020-04-28 09:45:08 > optimizer => Adam
[INFO] 2020-04-28 09:45:08 > lr => 0.001
[INFO] 2020-04-28 09:45:08 > clip_grads => False
[INFO] 2020-04-28 09:45:08 > batch_size => 64
[INFO] 2020-04-28 09:45:08 > epochs => 100
[INFO] 2020-04-28 09:45:08 > Transformer(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=128, out_features=1, bias=True)
          (w_2): Linear(in_features=1, out_features=128, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (feed_forward): Sequential(
            (0): Linear(in_features=128, out_features=1, bias=True)
            (1): Dropout(p=0.1, inplace=False)
            (2): ReLU()
            (3): Linear(in_features=1, out_features=128, bias=True)
            (4): Dropout(p=0.1, inplace=False)
          )
          (feed_forward_v1): Sequential(
            (0): Linear(in_features=128, out_features=1, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): Linear(in_features=1, out_features=128, bias=True)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm()
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): Linear(in_features=128, out_features=128, bias=True)
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=128, out_features=1, bias=True)
          (w_2): Linear(in_features=1, out_features=128, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (feed_forward): Sequential(
            (0): Linear(in_features=128, out_features=1, bias=True)
            (1): Dropout(p=0.1, inplace=False)
            (2): ReLU()
            (3): Linear(in_features=1, out_features=128, bias=True)
            (4): Dropout(p=0.1, inplace=False)
          )
          (feed_forward_v1): Sequential(
            (0): Linear(in_features=128, out_features=1, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): Linear(in_features=1, out_features=128, bias=True)
          )
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
    (generator): Generator(
      (proj): Linear(in_features=128, out_features=11, bias=True)
    )
  )
  (src_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(11, 128)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (tgt_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(11, 128)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (generator): Generator(
    (proj): Linear(in_features=128, out_features=11, bias=True)
  )
)
[INFO] 2020-04-28 09:45:08 > Training Epoch 0
